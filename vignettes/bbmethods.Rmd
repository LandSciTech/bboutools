---
title: "Analytic Methods for Estimation of Boreal Caribou Survival, Recruitment and Population Growth"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Analytic Methods for Estimation of Boreal Caribou Survival, Recruitment and Population Growth}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Bayesian vs Frequentist Framework

The frequentist (Maximum Likelihood) framework selects the parameter values which if they were true would be most likely to give rise to the data.
It assumes that all possible survival and recruitment values are equally likely to be true.
The confidence intervals (CIs) are invalid with small sample size.

The Bayesian framework selects parameter values which most likely to be true given the data. 
It allows incorporation of biological knowledge.
The credible intervals (CIs) represent the actual uncertainty irrespective of the sample size.

Most models can be fit in a Bayesian or frequentist framework.

## Fixed vs Random Effects

When a categorical variable is treated as a fixed effect each parameter value is estimated in isolation.
In contrast, when it is treated as a random effect the parameter values are assumed to be drawn from a common underlying distribution which allows the typical values to be estimated and each parameter estimate to be influenced by the other ones.  

The use of random effects is especially beneficial when some months/years have sparse or missing data. 
In the case of sparse data or extreme values, estimates will tend to be pulled toward the mean (i.e., 'shrinkage'). 
For missing data, the estimate will be equal to the mean. 
Shrinkage may not be desired if extreme values are likely to represent the true value (e.g., numerous wolf attacks in one year). 
In this case, a fixed effect model would yield better estimates. 

Fixed and random effects can be used in Bayesian or frequentist models. 

## Maximum Likelihood vs Posterior Probability

The frequentist approach simply identifies the parameter values that maximize the likelihood, i.e., have the greatest probability of having produced the data if they were true.
It does this by searching parameter space for the combination of parameter values with the Maximum Likelihood.
Parameter estimates for random effects can be estimated using the Laplace approximation (i.e., with software packages [TMB](https://arxiv.org/pdf/1509.00660.pdf) or [Nimble](https://r-nimble.org/html_manual/cha-AD.html#how-to-use-laplace-approximation)). 
The CIs are calculated using the standard errors, assuming that the likelihood is normally distributed.
This approach has the advantage of being fast.

The Bayesian approach multiplies the likelihood by the probability of the parameter values being true based on prior knowledge to get the posterior probability of the parameter values being true based on the data.
Bayesian methods repeatedly sample from the posterior probability distributions using MCMC (Monte Carlo Markov Chain) methods.
This approach has the advantage of allowing derived parameters such as the population growth rate to be accurately estimated from the primary survival and recruitment parameters.

## bboutools

`bboutools` provides the option to estimate parameter values using a Maximum Likelihood or a fully Bayesian approach. Random effects are used where appropriate by default. The Bayesian approach also uses biologically reasonable informative priors by default. 
`bboutools` provides relatively simple general models that can be used to compare survival, recruitment and population growth estimates across jurisdictions.

By default, the `bboutools` Bayesian method saves 1,000 MCMC samples from each of three chains (after discarding the first halves). The number of samples saved can be adjusted with the `niters` argument. 
With `niters` set, the user can simply increment the thinning rate as required to achieve convergence.
This process is automated in the Shiny app. 

### Survival Model

The survival model with annual random effect and trend is specified below in a simplified form of the BUGS language for readability.
The same model code is used for both the Bayesian and frequentist methods.

```
b0 ~ Normal(4, 2)
bYear ~ Normal(0, 1)

sMonth ~  Normal(0, 2) T(0,)
for(i in 1:nMonth)  bMonth[i] ~ Normal(0, sMonth)

sAnnual ~ Exponential(1)
for(i in 1:nAnnual)  bAnnual[i] ~ Normal(0, sAnnual)

for(i in 1:nObs) {
  logit(eSurvival[i]) = b0 + bMonth[Month[i]] + bAnnual[Annual[i]] + bYear * Year[i]
  Mortalities[i] ~ Binomial(1 - eSurvival[i], StartTotal[i])
}
```

### Recruitment Model

The recruitment model with annual random effect and year trend is specified below in a simplified form of the BUGS language for readability.

```
b0 ~ Normal(-1.4, 0.5)
bYear ~ Normal(0, 1)

adult_female_proportion ~ Beta(65, 35)

sAnnual ~  exponential(1)
for(i in 1:nAnnual)  bAnnual[i] ~ Normal(0, sAnnual)

for(i in 1:nObs) {
  FemaleYearlings[i] ~ Binomial(0.5, Yearlings[i])
  Cows[i] ~ Binomial(adult_female_proportion, CowsBulls[i])
  OtherAdultsFemales[i] ~ Binomial(adult_female_proportion, UnknownAdults[i])
  log(eRecruitment[i]) <- b0 + bAnnual[Annual[i]] + bYear * Year[i]
  AdultsFemales[i] <- max(FemaleYearlings[i] + Cows[i] + OtherAdultsFemales[i], 1)
  Calves[i] ~ Poisson(eRecruitment[i] * AdultsFemales[i])
}
```

In the frequentist approach, demographic stochasticity is removed from the model because it is not possible to estimate discrete latent variables using Laplace approximation. 
This has a minimal effect on estimates.
The adjusted model with no demographic stochasticity is specified below.

```
bYear ~ Normal(0, 1)

adult_female_proportion ~ Beta(65, 35)

sAnnual ~  exponential(1)
for(i in 1:nAnnual)  bAnnual[i] ~ Normal(0, sAnnual)

for(i in 1:nObs) {
  Cows[i] ~ Binomial(adult_female_proportion, CowsBulls[i])
  FemaleYearlings[i] <- 0.5 * Yearlings[i]
  OtherAdultsFemales[i] <- adult_female_proportion * UnknownAdults[i]
  log(eRecruitment[i]) <- b0 + bAnnual[Annual[i]] + bYear * Year[i]
  AdultsFemales[i] <- max(FemaleYearlings[i] + Cows[i] + OtherAdultsFemales[i], 1)
  Calves[i] ~ Poisson(eRecruitment[i] * AdultsFemales[i])
}
```

### `bboufit` Objects

The `bb_fit_survival()` and `bb_fit_recruitment()` functions use a Bayesian approach and return objects that inherit from class `bboufit`.

Objects of class `bboufit` have three elements: 

1. `model` - the compiled Nimble model as created by `nimble::nimbleModel()`.  
1. `model_code` - the model code in text format.  
1. `samples` - the MCMC samples generated from`nimble::runMCMC()` converted to an object of class `mcmcr`.  
1. `data` - the survival or recruitment data provided.

These are the raw materials for any further exploration or analysis. 
For example, view trace and density plots with `plot(fit$samples)`.

See [mcmcr](https://github.com/poissonconsulting/mcmcr) and [mcmcderive](https://github.com/poissonconsulting/mcmcderive) for working with `mcmcr` objects, or convert samples to an object of class `mcmc.list`, e,g, with `coda::as.mcmc.list` for working with the [coda](https://github.com/cran/coda) R package. 


### `bboufit_ml` Objects

The `bb_fit_survival_ml()` and `bb_fit_recruitment_ml()` functions use a Maximum Likelihood approach and return objects that inherit from class `bboufit_ml`.

Objects of class `bboufit_ml` have four elements: 

1. `model` - the Nimble model as created by `nimble::nimbleModel()`.   
1. `model_code` - the model code in text format.  
1. `mle` - the Maximum Likelihood output as created by model$findMLE().
1. `summary` - the summary of the Maximum Likelihood output as created by `model$summary(mle)`.  
1. `data` - the survival or recruitment data provided.

See [nimble](https://github.com/nimble-dev/nimble) for how to work with nimble model objects and Maximum Likelihood output. 

